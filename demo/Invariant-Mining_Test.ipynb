{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from loglizer.models import InvariantsMiner\n",
    "from loglizer import dataloader, preprocessing\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = '../data/HDFS/syslog_200000.log_structed.csv'\n",
    "struct_log = pd.read_csv(log_file, engine='c',\n",
    "                na_filter=False, memory_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventBlk = []\n",
    "eventBlks = {}\n",
    "for idx, row in struct_log.iterrows():\n",
    "    eventBlk.append(row['EventId'])\n",
    "    if (idx+1)%10 == 0:\n",
    "        eventBlks[(idx+1)//10] = eventBlk\n",
    "        eventBlk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(eventBlks.items(), columns=['BlockId', 'EventSequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_data(x_data, y_data=None, train_ratio=0, split_type='uniform'):\n",
    "    if split_type == 'uniform' and y_data is not None:\n",
    "        pos_idx = y_data > 0\n",
    "        x_pos = x_data[pos_idx]\n",
    "        y_pos = y_data[pos_idx]\n",
    "        x_neg = x_data[~pos_idx]\n",
    "        y_neg = y_data[~pos_idx]\n",
    "        train_pos = int(train_ratio * x_pos.shape[0])\n",
    "        train_neg = int(train_ratio * x_neg.shape[0])\n",
    "        x_train = np.hstack([x_pos[0:train_pos], x_neg[0:train_neg]])\n",
    "        y_train = np.hstack([y_pos[0:train_pos], y_neg[0:train_neg]])\n",
    "        x_test = np.hstack([x_pos[train_pos:], x_neg[train_neg:]])\n",
    "        y_test = np.hstack([y_pos[train_pos:], y_neg[train_neg:]])\n",
    "    elif split_type == 'sequential':\n",
    "        num_train = int(train_ratio * x_data.shape[0])\n",
    "        x_train = x_data[0:num_train]\n",
    "        x_test = x_data[num_train:]\n",
    "        if y_data is None:\n",
    "            y_train = None\n",
    "            y_test = None\n",
    "        else:\n",
    "            y_train = y_data[0:num_train]\n",
    "            y_test = y_data[num_train:]\n",
    "    # Random shuffle\n",
    "    indexes = shuffle(np.arange(x_train.shape[0]))\n",
    "    x_train = x_train[indexes]\n",
    "    if y_train is not None:\n",
    "        y_train = y_train[indexes]\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 19999 instances, train: 9999 instances, test: 10000 instances\n"
     ]
    }
   ],
   "source": [
    "x_data = data_df['EventSequence'].values\n",
    "\n",
    "train_ratio=0.5\n",
    "split_type='sequential'\n",
    "(x_train, _), (x_test, _) = _split_data(x_data, train_ratio=train_ratio, split_type=split_type)\n",
    "print('Total: {} instances, train: {} instances, test: {} instances'.format(\n",
    "      x_data.shape[0], x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariant Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Transformed train data summary ======\n",
      "Train data shape: 9999-by-127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "feature_extractor = preprocessing.FeatureExtractor()\n",
    "x_train = feature_extractor.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Model summary ======\n",
      "Invariant space dimension: 119\n",
      "Mined 119 invariants: {(15, 27): [1.0, -516.0], (3, 65): [-13.0, 1.0], (12, 78): [1.0, -15.0], (5, 112): [-4.0, 1.0], (24, 30): [1.0, -15.0], (21, 97): [1.0, -6.0], (4, 36): [1.0, -1.0], (25, 102): [1.0, -1.0], (25, 99): [1.0, -1.0], (3, 21): [-19.0, 1.0], (21, 70): [1.0, -19.0], (10, 123): [1.0, -615.0], (5, 54): [-2.0, 1.0], (11, 76): [-15.0, 1.0], (24, 82): [1.0, -15.0], (15, 55): [1.0, -172.0], (25, 74): [1.0, -1.0], (24, 64): [1.0, -2.0], (12, 59): [-1.0, 1.0], (12, 64): [1.0, -2.0], (11, 12): [-15.0, 1.0], (12, 103): [1.0, -15.0], (22, 54): [-5.0, 1.0], (5, 18): [1.0, -2.0], (9, 112): [-5.0, 1.0], (24, 47): [1.0, -15.0], (14, 38): [-2.0, 1.0], (11, 52): [-15.0, 1.0], (2, 118): [1.0, -2.0], (28, 97): [1.0, -16.0], (2, 56): [-1.0, 1.0], (4, 10): [-246.0, 1.0], (7, 109): [1.0, -2.0], (21, 26): [1.0, -5.0], (12, 45): [1.0, -15.0], (10, 13): [1.0, -614.0], (12, 25): [-1.0, 1.0], (25, 93): [-1.0, 1.0], (4, 16): [-2.0, 1.0], (17, 98): [1.0, -1.0], (25, 52): [1.0, -1.0], (24, 44): [1.0, -14.0], (10, 23): [1.0, -615.0], (10, 54): [1.0, -612.0], (26, 28): [-15.0, 1.0], (12, 46): [1.0, -15.0], (24, 73): [1.0, -1.0], (25, 125): [1.0, -1.0], (14, 49): [1.0, -1.0], (21, 117): [1.0, -19.0], (21, 32): [1.0, -19.0], (24, 124): [1.0, -1.0], (18, 105): [1.0, -2.0], (19, 122): [1.0, -1.0], (12, 108): [1.0, -15.0], (15, 33): [1.0, -516.0], (24, 78): [1.0, -15.0], (5, 111): [1.0, -2.0], (12, 30): [1.0, -15.0], (4, 89): [1.0, -1.0], (28, 32): [1.0, -11.0], (18, 66): [1.0, -2.0], (24, 91): [1.0, -15.0], (12, 47): [1.0, -15.0], (24, 103): [1.0, -15.0], (9, 111): [-2.0, 1.0], (24, 59): [-2.0, 1.0], (10, 83): [1.0, -615.0], (20, 126): [1.0, -2.0], (21, 35): [-31.0, 1.0], (28, 117): [1.0, -11.0], (24, 88): [1.0, -15.0], (12, 113): [1.0, -15.0], (24, 108): [1.0, -15.0], (11, 24): [-15.0, 1.0], (12, 124): [1.0, -1.0], (13, 107): [-8.0, 1.0], (12, 101): [1.0, -15.0], (21, 96): [1.0, -19.0], (26, 58): [-6.0, 1.0], (12, 44): [1.0, -14.0], (20, 81): [-2.0, 1.0], (11, 93): [-15.0, 1.0], (12, 63): [1.0, -15.0], (20, 115): [-1.0, 1.0], (7, 107): [-7.0, 1.0], (3, 58): [-22.0, 1.0], (14, 22): [-2.0, 1.0], (15, 80): [1.0, -129.0], (20, 110): [-1.0, 1.0], (12, 88): [1.0, -15.0], (26, 65): [-11.0, 1.0], (18, 79): [1.0, -2.0], (24, 101): [1.0, -15.0], (10, 42): [1.0, -615.0], (11, 99): [-15.0, 1.0], (25, 76): [1.0, -1.0], (20, 62): [-1.0, 1.0], (18, 39): [1.0, -2.0], (24, 104): [1.0, -15.0], (15, 72): [1.0, -516.0], (22, 29): [-3.0, 1.0], (11, 125): [-15.0, 1.0], (12, 73): [1.0, -1.0], (11, 102): [-15.0, 1.0], (12, 104): [1.0, -15.0], (11, 74): [-15.0, 1.0], (12, 84): [1.0, -15.0], (20, 54): [-4.0, 1.0], (25, 31): [1.0, -15.0], (24, 25): [1.0, -1.0], (28, 116): [1.0, -9.0], (24, 77): [1.0, -12.0], (26, 100): [-6.0, 1.0], (1, 61): [-34.0, 1.0], (15, 37): [1.0, -516.0], (3, 28): [-17.0, 1.0], (28, 70): [1.0, -11.0], (24, 63): [1.0, -15.0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model initialization and training\n",
    "epsilon = 0.5 # threshold for estimating invariant space\n",
    "model = InvariantsMiner(epsilon=epsilon)\n",
    "model.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict anomalies on the training set offline, and manually check for correctness\n",
    "y_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Transformed test data summary ======\n",
      "Test data shape: 10000-by-127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict anomalies on the test set to simulate the online mode\n",
    "# x_test may be loaded from another log file\n",
    "x_test = feature_extractor.transform(x_test)\n",
    "y_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = []\n",
    "anomalies_val = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] != 0:\n",
    "        anomalies.append(i)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] != 0:\n",
    "        anomalies.append(i + len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of log entries: 199990 | Total number of anomalies: 279\n",
      "Index of blocks that contains anomaly: \n",
      "[34, 54, 94, 146, 186, 190, 195, 258, 263, 271, 311, 325, 375, 383, 463, 543, 633, 654, 710, 788, 879, 1001, 1070, 1110, 1167, 1179, 1280, 1334, 1484, 1504, 1522, 1862, 1864, 1933, 1985, 1990, 1999, 2053, 2080, 2107, 2174, 2180, 2219, 2257, 2271, 2316, 2589, 2760, 2799, 2917, 2989, 2992, 3035, 3052, 3081, 3105, 3151, 3267, 3326, 3333, 3429, 3562, 3937, 4001, 4020, 4023, 4028, 4144, 4145, 4148, 4296, 4348, 4388, 4479, 4531, 4585, 4616, 4630, 4735, 4778, 4838, 4855, 4911, 5047, 5198, 5210, 5221, 5348, 5354, 5486, 5519, 5567, 5580, 5656, 5755, 5767, 5776, 5816, 6012, 6173, 6189, 6269, 6397, 6522, 6615, 6669, 6715, 6807, 6881, 6919, 7077, 7097, 7178, 7219, 7226, 7235, 7254, 7383, 7486, 7524, 7574, 7607, 7632, 7637, 7685, 7810, 7823, 7852, 8002, 8096, 8121, 8186, 8252, 8269, 8289, 8299, 8339, 8344, 8441, 8486, 8489, 8518, 8763, 8769, 8815, 8956, 8998, 9039, 9055, 9099, 9335, 9381, 9410, 9422, 9458, 9521, 9575, 9633, 9711, 9722, 9736, 9784, 9837, 9993, 11669, 14910, 14911, 14922, 14923, 14925, 15405, 15408, 15409, 15410, 15411, 15412, 15413, 15414, 15415, 15416, 15417, 15418, 15419, 15420, 15421, 15422, 15423, 15424, 15425, 15426, 15427, 15428, 15429, 15430, 15431, 15432, 15433, 15434, 15435, 15436, 15437, 15450, 15454, 15456, 15465, 15574, 15575, 15579, 15580, 15581, 15582, 15583, 17074, 17076, 17080, 17081, 17085, 17086, 17694, 17695, 17710, 17762, 17763, 17764, 17792, 17895, 17896, 17900, 17902, 17904, 17919, 17934, 17954, 17955, 18028, 18029, 18030, 18031, 18032, 18036, 18037, 18038, 18071, 18072, 18220, 18264, 18273, 18282, 18295, 18307, 18349, 18350, 18420, 18425, 18426, 18462, 18474, 18975, 18978, 18979, 18981, 18982, 18987, 18989, 18990, 19008, 19025, 19111, 19112, 19126, 19156, 19157, 19158, 19171, 19173, 19174, 19429, 19480, 19496]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of log entries: {} | Total number of anomalies: {}\".format(\n",
    "        10* (len(y_train) + len(y_test)),\n",
    "        len(anomalies)\n",
    "        )\n",
    "    )\n",
    "print(\"Index of blocks that contains anomaly: \\n{}\".format(anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intepretation of result\n",
    "\n",
    "Every value above in \"anomalies\" array is the index of block that has anomaly.\n",
    "\n",
    "Each block consists of 10 adjacnet log entries.\n",
    "\n",
    "Index i means there is an anomaly in log entries [i*10, (i+1)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "8c602af1-fee2-457c-90d7-c0db5a608002"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
